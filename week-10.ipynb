{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Quantitative Textual Analysis - Week 10\n",
    "\n",
    "## Diachronic corpora: Change over time (Brezina 2018, ch. 7)\n",
    "\n",
    "### Key terms\n",
    "\n",
    "- longitudinal study\n",
    "- diachronic corpora\n",
    "- lockwords\n",
    "- bootstrapping test\n",
    "\n",
    "### Visualization techniques\n",
    "\n",
    "- Line graph\n",
    "- Candlestick plot\n",
    "- Sparkline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-up: N-grams\n",
    "\n",
    "By now, we're all familiar with some charts created through Google's [Ngram Viewer](https://books.google.com/ngrams/). But what do these charts actually show us, and what are there limitations?\n",
    "\n",
    "Search for a few terms of your choosing in the Ngram Viewer. Try changing the time scale or zooming in and out.\n",
    "\n",
    "With a partner or in small groups, discuss the following questions:\n",
    "\n",
    "1. What do these n-grams show us?\n",
    "2. What corpus are they using?\n",
    "3. What are the limitations of this kind of charting?\n",
    "4. What data are we missing for more sophisticated analyses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colors over time\n",
    "\n",
    "In the ./data directory, you'll find 'colours-data.csv', a CSV dataset provided by Brezina. Each row has the year, followed by the relative frequencies of several colors for that year. We'll use these data to practice visualizing change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "%pip install altair pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import altair for visualization\n",
    "import altair as alt\n",
    "\n",
    "# import pandas for data-wrangling\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "colors_df = pd.read_csv(\"data/colours-data.csv\")\n",
    "colors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the table for easier charting\n",
    "value_vars = colors_df.columns.to_list()[1:]\n",
    "by_color = pd.melt(\n",
    "    colors_df, id_vars=[\"Year\"], value_vars=value_vars, value_name=\"relative frequency\"\n",
    ").rename(columns={\"variable\": \"color\"})\n",
    "\n",
    "by_color['Year'] = by_color['Year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart the data\n",
    "alt.Chart(by_color).mark_line(point=alt.OverlayMarkDef(filled=False, fill=\"white\")).encode(\n",
    "    x=\"Year:T\",\n",
    "    y=\"relative frequency:Q\",\n",
    "    color=alt.Color(\"color\").scale(None)\n",
    ").properties(width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "\n",
    "> Discuss: What kinds of information can you glean from this chart? How can you make the chart more useful?\n",
    "\n",
    "1. Using the [Altair](https://altair-viz.github.io/user_guide/data.html) docs, add a tooltip showing the year, color, and relative frequency when you hover over a point.\n",
    "2. The visualization helps very little for grey and blue -- can you figure out how to \"zoom in\" and get a meaningful sense of their change over time?\n",
    "3. Can you regroup the data by decade (e.g., `[1600, 1609], [1610, 1619], etc.`) and plot the results as a [box plot](https://altair-viz.github.io/user_guide/marks/boxplot.html)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping and percentage change\n",
    "\n",
    "In this section, we'll use the same dataset to explore \"bootstrapping,\" a \"process of multiple resampling\" that \"gives an insight into the amount of variation in the data and gives us the confidence to generalize from this sample\" [@Brezina2018 231].\n",
    "\n",
    "But first, let's start with a more intuitive method.\n",
    "\n",
    "## Percentage change\n",
    "\n",
    "```math\n",
    "\\text{\\% increase/decrease} = \\frac{\\text{relative frequency in corpus 2} - \\text{relative frequency in corpus 1}}{\\text{relative frequency in corpus 1}} \\times 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide our colors corpus in two halves by year, corresponding to the two halves of the 17th Century."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_df_1600_to_1649 = colors_df[colors_df['Year'].astype(int) <= 1649]\n",
    "colors_df_1650_to_1699 = colors_df[colors_df['Year'].astype(int) >= 1650]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the mean relative frequency per color to calculate the percentage change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_1600 = colors_df_1600_to_1649['red'].mean()\n",
    "red_1650 = colors_df_1650_to_1699['red'].mean()\n",
    "red_change = ((red_1650 - red_1600) / red_1600) * 100\n",
    "\n",
    "red_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "\n",
    "Perform the same calculations for the other colors. \n",
    "\n",
    "Can you generalize the calculation of percentage change by writing a function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap test\n",
    "\n",
    "\"The **bootstrap test** [proposed in [@Lijffijt.etal2016]] is a non-parametric test of statistical significance, ... which compares two corpora and computes the p-value associated with the comparison.\" [@Brezina2018 231–232]\n",
    "\n",
    "We can define the bootstrapping test mathematically as follows:\n",
    "\n",
    "```math\n",
    "\\text{p} = \\frac{1 + 2 \\times \\text{number of bootstrapping cycles} \\times \\text{(p1 or 1 – p1, whichever is smaller)}}{1 + \\text{number of bootstrapping cycles}}\n",
    "```\n",
    "\n",
    "where\n",
    "\n",
    "```math\n",
    "p1 = \\frac{\\text{For all boostrapping cycles sume of value H}}{\\text{number of boostrapping cycles}}\n",
    "```\n",
    "\n",
    "and where H can be 1 (value of interest in corpus1 > corpus2), 0.5 (value of interest in corpus1 == corpus2), or 0 (value of interest corpus1 < corpus2).\n",
    "\n",
    "**Note that resampling can include duplicates from the dataset.**\n",
    "\n",
    "Again, you'll find the data that we're working with in the data/ folder -- this time, we're using the \"bootstrap\" CSVs (again provided by Brezina)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/bootstrap_its.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "\n",
    "Calculate the p value for the bootstrap_*.csv data sets using Brezina's method. (Note that SciPy includes a `boostrap` method, but it differs from Brezina's definition.)\n",
    "\n",
    "Be sure to calculate Cohen's _d_ and the 95% Confidence Interval as well. Are your results the same as Brezina's?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
